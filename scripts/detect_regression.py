#!/usr/bin/env python3
"""
æ€§èƒ½å›å½’æ£€æµ‹è„šæœ¬
"""

import json
import sys
from typing import Dict, List, Tuple

# æ€§èƒ½å›å½’é˜ˆå€¼é…ç½®
THRESHOLDS = {
    'rps': {
        'warning': 0.10,  # 10% ä¸‹é™
        'failure': 0.10   # 10% ä¸‹é™
    },
    'latency': {
        'warning': 0.10,  # 10% å¢åŠ 
        'failure': 0.20   # 20% å¢åŠ 
    },
    'resources': {
        'warning': 0.10,  # 10% å¢åŠ 
        'failure': 0.20   # 20% å¢åŠ 
    }
}

# æ€§èƒ½åŸºå‡†å€¼
BASELINE = {
    'low_concurrent': {
        'rps': 17798,
        'latency_avg': 518,  # Î¼s
        'latency_p99': 1600,  # Î¼s
    },
    'medium_concurrent': {
        'rps': 17209,
        'latency_avg': 2790,  # Î¼s (2.79 ms)
        'latency_p99': 8500,  # Î¼s (8.5 ms)
    },
    'high_concurrent': {
        'rps': 16623,
        'latency_avg': 12200,  # Î¼s (12.2 ms)
        'latency_p99': 40000,  # Î¼s (40 ms)
    }
}

def detect_regression(current_data: Dict) -> Tuple[List[Dict], List[Dict], List[Dict]]:
    """
    æ£€æµ‹æ€§èƒ½å›å½’
    
    Args:
        current_data: å½“å‰æµ‹è¯•æ•°æ®
    
    Returns:
        (failures, warnings, improvements)
    """
    failures = []
    warnings = []
    improvements = []
    
    for scenario in current_data.get('test_scenarios', []):
        scenario_name = scenario['name']
        results = scenario['results']
        
        if scenario_name not in BASELINE:
            continue
        
        baseline = BASELINE[scenario_name]
        
        # æ£€æŸ¥ååé‡
        current_rps = results['rps']['value']
        baseline_rps = baseline['rps']
        rps_change = (current_rps - baseline_rps) / baseline_rps
        
        if rps_change < -THRESHOLDS['rps']['failure']:
            failures.append({
                'scenario': scenario_name,
                'metric': 'RPS',
                'current': current_rps,
                'baseline': baseline_rps,
                'change': rps_change * 100,
                'severity': 'failure'
            })
        elif rps_change < -THRESHOLDS['rps']['warning']:
            warnings.append({
                'scenario': scenario_name,
                'metric': 'RPS',
                'current': current_rps,
                'baseline': baseline_rps,
                'change': rps_change * 100,
                'severity': 'warning'
            })
        elif rps_change > THRESHOLDS['rps']['warning']:
            improvements.append({
                'scenario': scenario_name,
                'metric': 'RPS',
                'current': current_rps,
                'baseline': baseline_rps,
                'change': rps_change * 100,
                'severity': 'improvement'
            })
        
        # æ£€æŸ¥å¹³å‡å»¶è¿Ÿ
        current_latency_avg = results['latency_avg']['value']
        baseline_latency_avg = baseline['latency_avg']
        latency_avg_change = (current_latency_avg - baseline_latency_avg) / baseline_latency_avg
        
        if latency_avg_change > THRESHOLDS['latency']['failure']:
            failures.append({
                'scenario': scenario_name,
                'metric': 'Average Latency',
                'current': current_latency_avg,
                'baseline': baseline_latency_avg,
                'change': latency_avg_change * 100,
                'severity': 'failure'
            })
        elif latency_avg_change > THRESHOLDS['latency']['warning']:
            warnings.append({
                'scenario': scenario_name,
                'metric': 'Average Latency',
                'current': current_latency_avg,
                'baseline': baseline_latency_avg,
                'change': latency_avg_change * 100,
                'severity': 'warning'
            })
        elif latency_avg_change < -THRESHOLDS['latency']['warning']:
            improvements.append({
                'scenario': scenario_name,
                'metric': 'Average Latency',
                'current': current_latency_avg,
                'baseline': baseline_latency_avg,
                'change': latency_avg_change * 100,
                'severity': 'improvement'
            })
    
    return failures, warnings, improvements

def generate_report(failures: List[Dict], warnings: List[Dict], improvements: List[Dict]) -> str:
    """
    ç”Ÿæˆå›å½’æ£€æµ‹æŠ¥å‘Š
    
    Args:
        failures: å¤±è´¥åˆ—è¡¨
        warnings: è­¦å‘Šåˆ—è¡¨
        improvements: æ”¹è¿›åˆ—è¡¨
    
    Returns:
        Markdown æ ¼å¼çš„æŠ¥å‘Š
    """
    report = []
    
    if failures:
        report.append("## ğŸš¨ Performance Regressions Detected\n")
        for failure in failures:
            report.append(f"### {failure['scenario']}: {failure['metric']}\n")
            report.append(f"- **Current**: {failure['current']:.0f}\n")
            report.append(f"- **Baseline**: {failure['baseline']:.0f}\n")
            report.append(f"- **Change**: {failure['change']:.2f}%\n")
            report.append(f"- **Severity**: {failure['severity']}\n")
            report.append("\n")
    
    if warnings:
        report.append("## âš ï¸ Performance Warnings\n")
        for warning in warnings:
            report.append(f"### {warning['scenario']}: {warning['metric']}\n")
            report.append(f"- **Current**: {warning['current']:.0f}\n")
            report.append(f"- **Baseline**: {warning['baseline']:.0f}\n")
            report.append(f"- **Change**: {warning['change']:.2f}%\n")
            report.append(f"- **Severity**: {warning['severity']}\n")
            report.append("\n")
    
    if improvements:
        report.append("## ğŸ‰ Performance Improvements\n")
        for improvement in improvements:
            report.append(f"### {improvement['scenario']}: {improvement['metric']}\n")
            report.append(f"- **Current**: {improvement['current']:.0f}\n")
            report.append(f"- **Baseline**: {improvement['baseline']:.0f}\n")
            report.append(f"- **Change**: {improvement['change']:.2f}%\n")
            report.append(f"- **Severity**: {improvement['severity']}\n")
            report.append("\n")
    
    if not failures and not warnings and not improvements:
        report.append("## âœ… No Performance Changes Detected\n")
        report.append("All performance metrics are within acceptable ranges.\n")
    
    return ''.join(report)

def main():
    if len(sys.argv) < 2:
        print("Usage: python3 detect_regression.py <performance_results.json>")
        sys.exit(1)
    
    # åŠ è½½å½“å‰æµ‹è¯•æ•°æ®
    with open(sys.argv[1], 'r') as f:
        current_data = json.load(f)
    
    # æ£€æµ‹å›å½’
    failures, warnings, improvements = detect_regression(current_data)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_report(failures, warnings, improvements)
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    with open('regression_report.md', 'w') as f:
        f.write(report)
    
    # è¿”å›é€€å‡ºç 
    if failures:
        sys.exit(1)  # æœ‰å›å½’ï¼Œè¿”å›å¤±è´¥
    elif warnings:
        sys.exit(2)  # æœ‰è­¦å‘Šï¼Œè¿”å›è­¦å‘Š
    else:
        sys.exit(0)  # æ— é—®é¢˜ï¼Œè¿”å›æˆåŠŸ

if __name__ == '__main__':
    main()