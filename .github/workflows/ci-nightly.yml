name: CI/CD - Nightly Deep Test

# è§¦å‘æ¡ä»¶ï¼šæ¯æ—¥ UTC 0:00 è¿è¡Œï¼Œæˆ–æ‰‹åŠ¨è§¦å‘
on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

env:
  BUILD_TYPE: Debug
  ENABLE_COVERAGE: ON

jobs:
  # ========== é˜¶æ®µ 1: å¹¶è¡Œæž„å»ºå’Œæ‰«æ ==========
  
  ubuntu-build-all:
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4.1.1
        with:
          submodules: recursive
      
      - name: Setup build environment
        uses: ./.github/actions/setup-build
        with:
          os: ubuntu-latest
      
      - name: Cache dependencies
        uses: ./.github/actions/cache-deps
        with:
          cache-key: nightly-${{ github.run_number }}
          build-type: Debug
      
      - name: Configure CMake with coverage
        run: |
          cmake -B build -DCMAKE_BUILD_TYPE=Debug \
            -DENABLE_COVERAGE=ON \
            -DBUILD_WITH_WEBSOCKET=ON \
            -DBUILD_WITH_MIMALLOC=ON \
            -DCMAKE_C_FLAGS="--coverage" \
            -DCMAKE_CXX_FLAGS="--coverage"
      
      - name: Build
        run: |
          cmake --build build --config Debug -j$(nproc)
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4.3.1
        with:
          name: build-ubuntu-nightly-${{ github.run_number }}
          path: build/
          retention-days: 7
  
  code-quality-full:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4.1.1
        with:
          submodules: recursive
      
      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y cppcheck clang-tidy clang-format
      
      - name: Run cppcheck
        run: |
          cppcheck --enable=all --inconclusive --xml --xml-version=2 \
            --suppress=missingIncludeSystem \
            src/ include/ 2> cppcheck-results.xml || true
      
      - name: Run clang-tidy
        run: |
          find src/ -name "*.c" | xargs clang-tidy -p build/ || true
      
      - name: Check code formatting
        run: |
          find src/ include/ -name "*.c" -o -name "*.h" | xargs clang-format --dry-run --Werror || true
      
      - name: Upload quality results
        uses: actions/upload-artifact@v4.3.1
        with:
          name: code-quality-results-nightly-${{ github.run_number }}
          path: |
            cppcheck-results.xml
            clang-tidy-results.txt
          retention-days: 30
  
  security-scan-full:
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4.1.1
        with:
          submodules: recursive
      
      - name: Run CodeQL analysis
        uses: github/codeql-action/analyze@v3
        with:
          languages: cpp
      
      - name: Run dependency check
        run: |
          # æ£€æŸ¥ä¾èµ–åº“ç‰ˆæœ¬
          echo "Checking dependencies..."
      
      - name: Upload security results
        uses: actions/upload-artifact@v4.3.1
        with:
          name: security-results-nightly-${{ github.run_number }}
          path: |
            codeql-results/
            dependency-check-results.txt
          retention-days: 30
  
  # ========== é˜¶æ®µ 2: æ·±åº¦æµ‹è¯• ==========
  
  test-coverage:
    needs: [ubuntu-build-all]
    runs-on: ubuntu-latest
    timeout-minutes: 35
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4.1.1
        with:
          submodules: recursive
      
      - name: Download build artifacts
        uses: actions/download-artifact@v4.1.2
        with:
          name: build-ubuntu-nightly-${{ github.run_number }}
          path: build/
      
      - name: Run tests with coverage
        uses: ./.github/actions/run-tests
        with:
          build-dir: build
          test-type: coverage
          timeout: 120
          parallel: $(nproc)
      
      - name: Generate coverage report
        run: |
          cd build
          lcov --capture --directory . --output-file coverage.info
          lcov --remove coverage.info '/usr/*' --output-file coverage.info
          lcov --list coverage.info
          genhtml coverage.info --output-directory coverage-report
      
      - name: Upload coverage report
        uses: actions/upload-artifact@v4.3.1
        with:
          name: coverage-report-nightly-${{ github.run_number }}
          path: build/coverage-report/
          retention-days: 30
      
      - name: Upload coverage data
        uses: codecov/codecov-action@v4
        with:
          files: build/coverage.info
          flags: nightly
          name: nightly-coverage
  
  test-memory:
    needs: [ubuntu-build-all]
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4.1.1
        with:
          submodules: recursive
      
      - name: Download build artifacts
        uses: actions/download-artifact@v4.1.2
        with:
          name: build-ubuntu-nightly-${{ github.run_number }}
          path: build/
      
      - name: Configure with AddressSanitizer
        run: |
          cmake -B build-asan -DCMAKE_BUILD_TYPE=Debug \
            -DCMAKE_C_FLAGS="-fsanitize=address -fno-omit-frame-pointer" \
            -DCMAKE_CXX_FLAGS="-fsanitize=address -fno-omit-frame-pointer"
          cmake --build build-asan -j$(nproc)
      
      - name: Run tests with AddressSanitizer
        uses: ./.github/actions/run-tests
        with:
          build-dir: build-asan
          test-type: memory
          timeout: 120
          parallel: 1
      
      - name: Upload memory test results
        if: always()
        uses: actions/upload-artifact@v4.3.1
        with:
          name: memory-test-results-nightly-${{ github.run_number }}
          path: |
            build-asan/Testing/
            asan.log
          retention-days: 30
  
  test-stress:
    needs: [ubuntu-build-all]
    runs-on: ubuntu-latest
    timeout-minutes: 35
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4.1.1
        with:
          submodules: recursive
      
      - name: Download build artifacts
        uses: actions/download-artifact@v4.1.2
        with:
          name: build-ubuntu-nightly-${{ github.run_number }}
          path: build/
      
      - name: Install wrk
        run: |
          sudo apt-get update
          sudo apt-get install -y wrk
      
      - name: Run stress test
        run: |
          chmod +x build/dist/bin/benchmark_rps
          
          # å¯åŠ¨æœåŠ¡å™¨
          build/dist/bin/benchmark_rps > /tmp/server.log 2>&1 &
          SERVER_PID=$!
          sleep 3
          
          # æŒç»­é«˜è´Ÿè½½æµ‹è¯•ï¼ˆ5åˆ†é’Ÿï¼‰
          wrk -t8 -c500 -d300s --timeout 10s http://localhost:18081/ > stress-test.log 2>&1 || true
          
          kill $SERVER_PID 2>/dev/null || true
      
      - name: Upload stress test results
        uses: actions/upload-artifact@v4.3.1
        with:
          name: stress-test-results-nightly-${{ github.run_number }}
          path: |
            stress-test.log
            /tmp/server.log
          retention-days: 30
  
  performance-full:
    needs: [ubuntu-build-all]
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4.1.1
        with:
          submodules: recursive
      
      - name: Download build artifacts
        uses: actions/download-artifact@v4.1.2
        with:
          name: build-ubuntu-nightly-${{ github.run_number }}
          path: build/
      
      - name: Install wrk and tools
        run: |
          sudo apt-get update
          sudo apt-get install -y wrk python3 python3-pip
          pip3 install matplotlib numpy
      
      - name: Run full performance benchmark
        run: |
          chmod +x build/dist/bin/benchmark_rps
          
          # å¯åŠ¨æœåŠ¡å™¨
          build/dist/bin/benchmark_rps > /tmp/server.log 2>&1 &
          SERVER_PID=$!
          sleep 3
          
          # 8ä¸ªæµ‹è¯•åœºæ™¯ï¼Œå¤šæ¬¡è¿­ä»£
          cat > performance-tests.sh << 'EOF'
          #!/bin/bash
          echo "=== Performance Test Results ===" > performance.log
          
          # åœºæ™¯ 1: ä½Žå¹¶å‘ï¼ˆ3æ¬¡å–å¹³å‡ï¼‰
          echo "Test 1: Low concurrency (10 connections)" >> performance.log
          for i in {1..3}; do
            wrk -t2 -c10 -d10s http://localhost:18081/ >> performance.log
            sleep 2
          done
          
          # åœºæ™¯ 2: ä¸­å¹¶å‘ï¼ˆ3æ¬¡å–å¹³å‡ï¼‰
          echo "Test 2: Medium concurrency (50 connections)" >> performance.log
          for i in {1..3}; do
            wrk -t4 -c50 -d10s http://localhost:18081/ >> performance.log
            sleep 2
          done
          
          # åœºæ™¯ 3: é«˜å¹¶å‘ï¼ˆ3æ¬¡å–å¹³å‡ï¼‰
          echo "Test 3: High concurrency (200 connections)" >> performance.log
          for i in {1..3}; do
            wrk -t8 -c200 -d10s http://localhost:18081/ >> performance.log
            sleep 2
          done
          
          # åœºæ™¯ 4: æžç«¯å¹¶å‘ï¼ˆ2æ¬¡å–å¹³å‡ï¼‰
          echo "Test 4: Extreme concurrency (500 connections)" >> performance.log
          for i in {1..2}; do
            wrk -t8 -c500 -d30s http://localhost:18081/ >> performance.log
            sleep 5
          done
          
          # åœºæ™¯ 5: è¶…é«˜å¹¶å‘ï¼ˆ2æ¬¡å–å¹³å‡ï¼‰
          echo "Test 5: Very high concurrency (1000 connections)" >> performance.log
          for i in {1..2}; do
            wrk -t8 -c1000 -d30s http://localhost:18081/ >> performance.log
            sleep 5
          done
          
          # åœºæ™¯ 6: æŒç»­è´Ÿè½½ï¼ˆ1æ¬¡ï¼‰
          echo "Test 6: Sustained load (100 connections, 60 seconds)" >> performance.log
          wrk -t4 -c100 -d60s http://localhost:18081/ >> performance.log
          
          # åœºæ™¯ 7: å°æ–‡ä»¶ï¼ˆ2æ¬¡å–å¹³å‡ï¼‰
          echo "Test 7: Small file transfer (100 connections)" >> performance.log
          for i in {1..2}; do
            wrk -t4 -c100 -d10s http://localhost:18081/ >> performance.log
            sleep 2
          done
          
          # åœºæ™¯ 8: å¤§æ–‡ä»¶ï¼ˆ2æ¬¡å–å¹³å‡ï¼‰
          echo "Test 8: Large file transfer (50 connections)" >> performance.log
          for i in {1..2}; do
            wrk -t4 -c50 -d10s http://localhost:18081/ >> performance.log
            sleep 2
          done
          EOF
          
          chmod +x performance-tests.sh
          ./performance-tests.sh
          
          kill $SERVER_PID 2>/dev/null || true
      
      - name: Parse performance results
        id: parse
        run: |
          python3 << 'EOF'
          import re
          import json
          
          results = {}
          with open('performance.log', 'r') as f:
              content = f.read()
              
          # è§£æžæ¯ä¸ªæµ‹è¯•çš„ç»“æžœ
          tests = re.split(r'Test \d+:', content)[1:]
          for i, test in enumerate(tests):
              rps_match = re.search(r'Requests/sec:\s+([\d.]+)', test)
              latency_match = re.search(r'Latency\s+([\d.]+[a-z]+)', test)
              
              if rps_match:
                  results[f'test_{i+1}'] = {
                      'rps': float(rps_match.group(1)),
                      'latency': latency_match.group(1) if latency_match else 'N/A'
                  }
          
          with open('performance-results.json', 'w') as f:
              json.dump({
                  'timestamp': '${{ github.event.head_commit.timestamp }}',
                  'commit': '${{ github.sha }}',
                  'results': results
              }, f, indent=2)
          
          print(f"parsed={len(results)} tests")
          EOF
      
      - name: Generate performance trend report
        run: |
          cat > performance-trend.md << 'EOF'
          # Nightly Performance Trend Report
          
          - **Date**: ${{ github.event.head_commit.timestamp }}
          - **Commit**: ${{ github.sha }}
          - **Run**: #${{ github.run_number }}
          
          ## Test Results
          
          | Test | RPS | Latency |
          |------|-----|---------|
          
          EOF
          
          # æ·»åŠ æµ‹è¯•ç»“æžœè¡¨æ ¼
          python3 << 'EOF'
          import json
          
          with open('performance-results.json', 'r') as f:
              data = json.load(f)
          
          test_names = {
              'test_1': 'Low Concurrent (10)',
              'test_2': 'Medium Concurrent (50)',
              'test_3': 'High Concurrent (100)',
              'test_4': 'Extreme Concurrent (500)',
              'test_5': 'Very High Concurrent (1000)',
              'test_6': 'Sustained Load',
              'test_7': 'Small File',
              'test_8': 'Large File'
          }
          
          with open('performance-trend.md', 'a') as f:
              for test_id, result in data['results'].items():
                  name = test_names.get(test_id, test_id)
                  f.write(f"| {name} | {result['rps']:.2f} | {result['latency']} |\n")
          EOF
      
      - name: Upload performance artifacts
        uses: actions/upload-artifact@v4.3.1
        with:
          name: performance-full-nightly-${{ github.run_number }}
          path: |
            performance-results.json
            performance-trend.md
            performance.log
          retention-days: 30
  
  # ========== é˜¶æ®µ 3: ç”ŸæˆæŠ¥å‘Š ==========
  
  generate-nightly-report:
    needs: [test-coverage, test-memory, test-stress, performance-full]
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: always()
    
    steps:
      - name: Generate nightly summary
        run: |
          echo "## ðŸŒ™ Nightly Test Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Status" >> $GITHUB_STEP_SUMMARY
          echo "| Category | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Coverage | ${{ needs.test-coverage.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Memory Test | ${{ needs.test-memory.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Stress Test | ${{ needs.test-stress.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance | ${{ needs.performance-full.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- [Coverage Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- [Performance Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- [Memory Test Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- [Stress Test Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
      
      - name: Download all artifacts
        run: |
          gh run download ${{ github.run_id }} --pattern "*nightly-${{ github.run_number }}*" -D /tmp/artifacts
        env:
          GH_TOKEN: ${{ github.token }}
      
      - name: Create nightly release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: nightly-${{ github.run_number }}
          name: Nightly Build - ${{ github.event.head_commit.timestamp }}
          body_path: performance-trend.md
          draft: false
          prerelease: true
          files: |
            /tmp/artifacts/*
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
