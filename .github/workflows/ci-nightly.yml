name: CI/CD - Nightly Deep Test

# Ëß¶ÂèëÊù°‰ª∂ÔºöÊØèÊó• UTC 0:00 ËøêË°åÔºåÊàñÊâãÂä®Ëß¶Âèë
on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

env:
  BUILD_TYPE: Debug
  ENABLE_COVERAGE: ON

jobs:
  # ========== Èò∂ÊÆµ 1: Âπ∂Ë°åÊûÑÂª∫ÂíåÊâ´Êèè ==========
  
  ubuntu-build-all:
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: recursive
      
      - name: Setup build environment
        uses: ./.github/actions/setup-build
        with:
          os: ubuntu-latest
      
      - name: Cache dependencies
        uses: ./.github/actions/cache-deps
        with:
          cache-key: nightly-${{ github.run_number }}
          build-type: Debug
      
      - name: Configure CMake with coverage
        run: |
          cmake -B build -DCMAKE_BUILD_TYPE=Debug \
            -DENABLE_COVERAGE=ON \
            -DBUILD_WITH_WEBSOCKET=ON \
            -DBUILD_WITH_MIMALLOC=ON \
            -DCMAKE_C_FLAGS="--coverage" \
            -DCMAKE_CXX_FLAGS="--coverage"
      
      - name: Build
        run: |
          cmake --build build --config Debug -j$(nproc)
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-ubuntu-nightly-${{ github.run_number }}
          path: build/
          retention-days: 7
  
  code-quality-full:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: recursive
      
      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y cppcheck clang-tidy clang-format
      
      - name: Run cppcheck
        run: |
          cppcheck --enable=all --inconclusive --xml --xml-version=2 \
            --suppress=missingIncludeSystem \
            src/ include/ 2> cppcheck-results.xml || true
      
      - name: Run clang-tidy
        run: |
          find src/ -name "*.c" | xargs clang-tidy -p build/ || true
      
      - name: Check code formatting
        run: |
          find src/ include/ -name "*.c" -o -name "*.h" | xargs clang-format --dry-run --Werror || true
      
      - name: Upload quality results
        uses: actions/upload-artifact@v4
        with:
          name: code-quality-results-nightly-${{ github.run_number }}
          path: |
            cppcheck-results.xml
            clang-tidy-results.txt
          retention-days: 30
  
  security-scan-full:
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: recursive
      
      - name: Run CodeQL analysis
        uses: github/codeql-action/analyze@v4
        with:
          languages: cpp
      
      - name: Run dependency check
        run: |
          # Ê£ÄÊü•‰æùËµñÂ∫ìÁâàÊú¨
          echo "Checking dependencies..."
      
      - name: Upload security results
        uses: actions/upload-artifact@v4
        with:
          name: security-results-nightly-${{ github.run_number }}
          path: |
            codeql-results/
            dependency-check-results.txt
          retention-days: 30
  
  # ========== Èò∂ÊÆµ 2: Ê∑±Â∫¶ÊµãËØï ==========
  
  test-coverage:
    needs: [ubuntu-build-all]
    runs-on: ubuntu-latest
    timeout-minutes: 35
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: recursive
      
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-ubuntu-nightly-${{ github.run_number }}
          path: build/
      
      - name: Run tests with coverage
        run: |
          cd build
          ctest --output-on-failure -j$(nproc) --timeout 120
      
      - name: Generate coverage report
        run: |
          cd build
          lcov --capture --directory . --output-file coverage.info
          lcov --remove coverage.info '/usr/*' --output-file coverage.info
          lcov --list coverage.info
          genhtml coverage.info --output-directory coverage-report
      
      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-nightly-${{ github.run_number }}
          path: build/coverage-report/
          retention-days: 30
      
      - name: Upload coverage data
        uses: codecov/codecov-action@v4
        with:
          files: build/coverage.info
          flags: nightly
          name: nightly-coverage
  
  test-memory:
    needs: [ubuntu-build-all]
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: recursive
      
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-ubuntu-nightly-${{ github.run_number }}
          path: build/
      
      - name: Configure with AddressSanitizer
        run: |
          cmake -B build-asan -DCMAKE_BUILD_TYPE=Debug \
            -DCMAKE_C_FLAGS="-fsanitize=address -fno-omit-frame-pointer" \
            -DCMAKE_CXX_FLAGS="-fsanitize=address -fno-omit-frame-pointer"
          cmake --build build-asan -j$(nproc)
      
      - name: Run tests with AddressSanitizer
        run: |
          cd build-asan
          ASAN_OPTIONS=detect_leaks=1:halt_on_error=0 ctest --output-on-failure -j1
      
      - name: Upload memory test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: memory-test-results-nightly-${{ github.run_number }}
          path: |
            build-asan/Testing/
            asan.log
          retention-days: 30
  
  test-stress:
    needs: [ubuntu-build-all]
    runs-on: ubuntu-latest
    timeout-minutes: 35
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: recursive
      
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-ubuntu-nightly-${{ github.run_number }}
          path: build/
      
      - name: Install wrk
        run: |
          sudo apt-get update
          sudo apt-get install -y wrk
      
      - name: Run stress test
        run: |
          chmod +x build/dist/bin/performance_static_server
          mkdir -p build/public
          echo "<html><body><h1>Stress Test</h1></body></html>" > build/public/index.html
          
          # ÂêØÂä®ÊúçÂä°Âô®
          build/dist/bin/performance_static_server -d build/public -p 8080 > /tmp/server.log 2>&1 &
          SERVER_PID=$!
          sleep 3
          
          # ÊåÅÁª≠È´òË¥üËΩΩÊµãËØïÔºà5ÂàÜÈíüÔºâ
          wrk -t8 -c500 -d300s --timeout 10s http://localhost:8080/ > stress-test.log
          
          kill $SERVER_PID 2>/dev/null || true
      
      - name: Upload stress test results
        uses: actions/upload-artifact@v4
        with:
          name: stress-test-results-nightly-${{ github.run_number }}
          path: |
            stress-test.log
            /tmp/server.log
          retention-days: 30
  
  performance-full:
    needs: [ubuntu-build-all]
    runs-on: ubuntu-latest
    timeout-minutes: 50
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: recursive
      
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-ubuntu-nightly-${{ github.run_number }}
          path: build/
      
      - name: Install wrk and tools
        run: |
          sudo apt-get update
          sudo apt-get install -y wrk python3 python3-pip
          pip3 install matplotlib numpy
      
      - name: Run full performance benchmark
        run: |
          chmod +x build/dist/bin/performance_static_server
          mkdir -p build/public
          echo "<html><body><h1>Performance Test</h1></body></html>" > build/public/index.html
          
          # ÂêØÂä®ÊúçÂä°Âô®
          build/dist/bin/performance_static_server -d build/public -p 8080 > /tmp/server.log 2>&1 &
          SERVER_PID=$!
          sleep 3
          
          # 8‰∏™ÊµãËØïÂú∫ÊôØÔºåÂ§öÊ¨°Ëø≠‰ª£
          cat > performance-tests.sh << 'EOF'
          #!/bin/bash
          echo "=== Performance Test Results ===" > performance.log
          
          # Âú∫ÊôØ 1: ‰ΩéÂπ∂Âèë
          echo "Test 1: Low concurrency (10 connections)" >> performance.log
          wrk -t4 -c10 -d10s http://localhost:8080/ >> performance.log
          
          # Âú∫ÊôØ 2: ‰∏≠Âπ∂Âèë
          echo "Test 2: Medium concurrency (50 connections)" >> performance.log
          wrk -t4 -c50 -d10s http://localhost:8080/ >> performance.log
          
          # Âú∫ÊôØ 3: È´òÂπ∂Âèë
          echo "Test 3: High concurrency (100 connections)" >> performance.log
          wrk -t4 -c100 -d10s http://localhost:8080/ >> performance.log
          
          # Âú∫ÊôØ 4: ÊûÅÁ´ØÂπ∂Âèë
          echo "Test 4: Extreme concurrency (500 connections)" >> performance.log
          wrk -t8 -c500 -d30s http://localhost:8080/ >> performance.log
          
          # Âú∫ÊôØ 5: Ë∂ÖÈ´òÂπ∂Âèë
          echo "Test 5: Very high concurrency (1000 connections)" >> performance.log
          wrk -t8 -c1000 -d30s http://localhost:8080/ >> performance.log
          
          # Âú∫ÊôØ 6: ÊåÅÁª≠Ë¥üËΩΩ
          echo "Test 6: Sustained load (60 seconds)" >> performance.log
          wrk -t4 -c100 -d60s http://localhost:8080/ >> performance.log
          
          # Âú∫ÊôØ 7: Â∞èÊñá‰ª∂
          echo "Test 7: Small file transfer" >> performance.log
          wrk -t4 -c100 -d10s http://localhost:8080/ >> performance.log
          
          # Âú∫ÊôØ 8: Â§ßÊñá‰ª∂
          echo "Test 8: Large file transfer" >> performance.log
          wrk -t4 -c50 -d10s http://localhost:8080/ >> performance.log
          EOF
          
          chmod +x performance-tests.sh
          ./performance-tests.sh
          
          kill $SERVER_PID 2>/dev/null || true
      
      - name: Parse performance results
        id: parse
        run: |
          python3 << 'EOF'
          import re
          import json
          
          results = {}
          with open('performance.log', 'r') as f:
              content = f.read()
              
          # Ëß£ÊûêÊØè‰∏™ÊµãËØïÁöÑÁªìÊûú
          tests = re.split(r'Test \d+:', content)[1:]
          for i, test in enumerate(tests):
              rps_match = re.search(r'Requests/sec:\s+([\d.]+)', test)
              latency_match = re.search(r'Latency\s+([\d.]+[a-z]+)', test)
              
              if rps_match:
                  results[f'test_{i+1}'] = {
                      'rps': float(rps_match.group(1)),
                      'latency': latency_match.group(1) if latency_match else 'N/A'
                  }
          
          with open('performance-results.json', 'w') as f:
              json.dump({
                  'timestamp': '${{ github.event.head_commit.timestamp }}',
                  'commit': '${{ github.sha }}',
                  'results': results
              }, f, indent=2)
          
          print(f"parsed={len(results)} tests")
          EOF
      
      - name: Generate performance trend report
        run: |
          cat > performance-trend.md << 'EOF'
          # Nightly Performance Trend Report
          
          - **Date**: ${{ github.event.head_commit.timestamp }}
          - **Commit**: ${{ github.sha }}
          - **Run**: #${{ github.run_number }}
          
          ## Test Results
          
          | Test | RPS | Latency |
          |------|-----|---------|
          
          EOF
          
          # Ê∑ªÂä†ÊµãËØïÁªìÊûúË°®Ê†º
          python3 << 'EOF'
          import json
          
          with open('performance-results.json', 'r') as f:
              data = json.load(f)
          
          test_names = {
              'test_1': 'Low Concurrent (10)',
              'test_2': 'Medium Concurrent (50)',
              'test_3': 'High Concurrent (100)',
              'test_4': 'Extreme Concurrent (500)',
              'test_5': 'Very High Concurrent (1000)',
              'test_6': 'Sustained Load',
              'test_7': 'Small File',
              'test_8': 'Large File'
          }
          
          with open('performance-trend.md', 'a') as f:
              for test_id, result in data['results'].items():
                  name = test_names.get(test_id, test_id)
                  f.write(f"| {name} | {result['rps']:.2f} | {result['latency']} |\n")
          EOF
      
      - name: Upload performance artifacts
        uses: actions/upload-artifact@v4
        with:
          name: performance-full-nightly-${{ github.run_number }}
          path: |
            performance-results.json
            performance-trend.md
            performance.log
          retention-days: 90
  
  # ========== Èò∂ÊÆµ 3: ÁîüÊàêÊä•Âëä ==========
  
  generate-nightly-report:
    needs: [test-coverage, test-memory, test-stress, performance-full]
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: always()
    
    steps:
      - name: Generate nightly summary
        run: |
          echo "## üåô Nightly Test Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Status" >> $GITHUB_STEP_SUMMARY
          echo "| Category | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Coverage | ${{ needs.test-coverage.result == 'success' && '‚úÖ' || '‚ùå' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Memory Test | ${{ needs.test-memory.result == 'success' && '‚úÖ' || '‚ùå' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Stress Test | ${{ needs.test-stress.result == 'success' && '‚úÖ' || '‚ùå' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance | ${{ needs.performance-full.result == 'success' && '‚úÖ' || '‚ùå' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- [Coverage Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- [Performance Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- [Memory Test Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- [Stress Test Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
      
      - name: Download all artifacts
        run: |
          gh run download ${{ github.run_id }} --pattern "*nightly-${{ github.run_number }}*" -D /tmp/artifacts
        env:
          GH_TOKEN: ${{ github.token }}
      
      - name: Create nightly release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: nightly-${{ github.run_number }}
          name: Nightly Build - ${{ github.event.head_commit.timestamp }}
          body_path: performance-trend.md
          draft: false
          prerelease: true
          files: |
            /tmp/artifacts/*
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
